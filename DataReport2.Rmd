---
title: "BIOL3207 Data Report 2"
author: "u6956268"
date: "`r Sys.Date()`"
output: 
  bookdown::html_document2:
    code_folding: show
    number_sections: no
    toc: yes
    toc_depth: 6
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load packages
```{r}
library(pacman)
p_load(bookdown, tidyverse, flextable, metafor, orchaRd)
```

Analysis of OA_activitydat_20190302_BIOL3207.csv to generate summary statistics (mean, SD, N) for each fish species average activity for each treatment
```{r}
data <- read_csv("OA_activitydat_20190302_BIOL3207.csv")
data_clean <- data[which(complete.cases(data)),] # Remove data points which are incomplete
data_clean <- select(data_clean, -...1) # Remove irrelevant column

summary_stats <- data_clean %>% group_by(species, treatment) %>% summarise(n(), mean(activity), sd(activity))
summary_stats <- pivot_wider(data=summary_stats, names_from="treatment", values_from=c("n()", "mean(activity)", "sd(activity)"))
summary_stats
```

Merge these summary statistics with the meta-data in clark_paper_data.csv
```{r}
clark_data <- read_csv("clark_paper_data.csv")
clark_data <- clark_data %>% slice(rep(1:n(), each = 6)) #Copy row of info 6 times according to formatting of meta-analysis data set

clark_data <- mutate(clark_data, Species=summary_stats$species, .after=10)
clark_data[which(clark_data$Species=="acantho"),]$Species <- "Acanthochromis polyacanthus"
clark_data[which(clark_data$Species=="ambon"),]$Species <- "Pomacentrus amboinensis"
clark_data[which(clark_data$Species=="chromis"),]$Species <- "Chromis atripectoralis"
clark_data[which(clark_data$Species=="humbug"),]$Species <- "Dascyllus aruanus"
clark_data[which(clark_data$Species=="lemon"),]$Species <- "Pomacentrus moluccensis"
clark_data[which(clark_data$Species=="whitedams"),]$Species <- "Dischistodus perspicillatus"

clark_data <- mutate(clark_data, 
                    ctrl.n=summary_stats$`n()_control`, 
                    ctrl.mean=summary_stats$`mean(activity)_control`, 
                    ctrl.sd=summary_stats$`sd(activity)_control`, 
                    oa.n=summary_stats$`n()_CO2`, 
                    oa.mean=summary_stats$`mean(activity)_CO2`, 
                    oa.sd=summary_stats$`sd(activity)_CO2`)
clark_data
```

Merge this combined summary statistics/meta-data with the larger meta-analysis data set in ocean_meta_data.csv
```{r}
meta_data <- read_csv("ocean_meta_data.csv")
clark_data$`Pub year IF` <- as.character(clark_data$`Pub year IF`) #Changing variable class to character to match meta-analysis data set 
clark_data$`2017 IF` <- as.character(clark_data$`2017 IF`) #Changing variable class to character to match meta-analysis data set 

meta_data <- full_join(meta_data, clark_data)
summary(meta_data)
```

```{r}
ggplot(meta_data, aes(x=ctrl.mean, y=oa.mean))+
  geom_point()
```

From the data summary and plot there are two clear outlier data points with very high means for both the control and treatment conditions. This will dramatically skew the data if left in, so these two points will be removed. 

```{r}
meta_data <- meta_data %>% filter(meta_data$ctrl.mean<25000 & meta_data$oa.mean<25000)
```


Calculate the log response ratio (lnRR) effect size for every row of the dataframe using metafor’s escalc() function
```{r}
corr_stats <- cor.test(meta_data$ctrl.mean, meta_data$oa.mean, method="pearson")
meta_data$r_corr <- corr_stats$estimate
effect_sizes <- metafor::escalc(measure = "ROM", 
                                n1i = ctrl.n, n2i = oa.n,
                                m1i = ctrl.mean, m2i = oa.mean, 
                                sd1i = ctrl.sd, sd2i = oa.sd, 
                                ri = r_corr,
                                data = meta_data)
effect_sizes <- effect_sizes %>% mutate(residual = 1:n())
```

Meta-analytic model fitted to the data that controls for the sampling variance of lnRR. The model should include a random effect of study and observation. Use metafor’s rma.mv() function.
```{r}
model <- metafor::rma.mv(data=effect_sizes, yi=yi, V=vi, 
                         random=list(~1|Study,
                                     ~1|Behavioural.metric))
model
```

```{r}
orchaRd::i2_ml(model, data = effect_sizes)
```


Written paragraph about the findings and what they mean. Support with a figure. Correct presentation and interpretation of overall meta-analytic mean and measures of uncertainty around the mean estimate (e.g., 95% confidence intervals). Measures of heterogeneity in effect size estimates across studies (i.e., I2 and/or prediction intervals - see predict() function in metafor). Forest plot showing the mean estimate, 95% confidence interval, and prediction interval with clearly labelled axes, number of samples and studies plotted on figure

Overall meta-analytic mean is -0.1845. This means that for every 1 increase in the control mean, the treatment mean increases by 0.8155. 
95% confidence interval is -0.4066 to 0.0375. This confidence interval includes 0 which is the null hypothesis so there is no statistical significance. It is very possible that there is no difference between the control and treatment conditions. 
There is a significant amount of heterogeneity among effects, with Q=736,088,491, df=798, p=<0.0001. Proportion of variance among effects after removing sampling variation is 100%. Differences between studies explains 12% of the effect size variation, and differences between Behavioural metric explains 88% of the effect size variation. 

Generate funnel plot. Visually assess the possibility of publication bias.
```{r}
metafor::funnel(x = effect_sizes$yi, vi = effect_sizes$vi, 
                yaxis = "seinv", digits = 2, 
                level = c(0.1, 0.05, 0.01), 
                shade = c("white", "gray55", "gray 75"), las = 1, 
                xlab = "Correlation Coefficient (r)", legend = TRUE)
```


Generate a time-lag plot. Assess how effect sizes may or may not have changed through time.
```{r}

```


Formal meta-regression model that includes year as a moderator (fixed effect) to test for time-lag bias.

Formal meta-regression model that includes inverse sampling variance (1/variance of log response ratio) to test for file-drawer biases

Written paragraph about the meta-regression results. What type of publication bias, if any, appears to be present in the data? If publication bias is present, what does it mean and what might be contributing to such bias?

Identify any studies contributing to publication bias. How do your updated meta-analysis results compare with a meta-analysis by Clement et al? Are there any concerns about these studies? If so, describe using references to existing papers what concerns have been raised?

